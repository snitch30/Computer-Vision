# -*- coding: utf-8 -*-

Automatically generated by Colaboratory.


# Initial Setup
This Jupyter Notebook was successfully run in Google Colab, and input files were located on the same directory as the code. Although none of the google colab specific libraries were used to do this part of the assignment.

# Semantic segmentation (10 marks)
Read paper Fully Convolutional Networks for Semantic Segmentation (https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf). From the class drive download script segmentation.py, containing example how to use pretrained models for semantic segmentation.

a) Briefly explain:
   
i) How FCN upsamples predictions to match the original image size.

> As an efficient, effective alternative, the authors introduce deconvolution (also known as backwards strided convolution) layers for upsampling. The authors also suggest that in-network upsampling is fast and effective for learning dense prediction.

ii) How had the authors improved the coarse predictions produced by the deepest layer.

> The authors had improved the coarse predictions produced by the deepest layer by combining the final prediction layer with the lower prediction layers and finer strides with non-linear feature heirarchy known as _deep jet_. Also the authors claim multi-resolution layer combinations dramatically improves the performance while simultaneously simplifying and speeding up the learning.
"""

# -*- coding: utf-8 -*-
"""
Based on code from
    https://colab.research.google.com/github/spmallick/learnopencv/blob/master/PyTorch-Segmentation-torchvision/intro-seg.ipynb
"""

from PIL import Image
import matplotlib.pyplot as plt
import torch
from torchvision import models
import numpy as np
import torchvision.transforms as T
import cv2


def decode_segmap(image, nc=21):
  
  label_colors = np.array([(0, 0, 0),  # 0=background
               # 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle
               (128, 0, 0), (0, 128, 0), (128, 128, 0), (0, 0, 128), (128, 0, 128),
               # 6=bus, 7=car, 8=cat, 9=chair, 10=cow
               (0, 128, 128), (128, 128, 128), (64, 0, 0), (192, 0, 0), (64, 128, 0),
               # 11=dining table, 12=dog, 13=horse, 14=motorbike, 15=person
               (192, 128, 0), (64, 0, 128), (192, 0, 128), (64, 128, 128), (192, 128, 128),
               # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor
               (0, 64, 0), (128, 64, 0), (0, 192, 0), (128, 192, 0), (0, 64, 128)])

  r = np.zeros_like(image).astype(np.uint8)
  g = np.zeros_like(image).astype(np.uint8)
  b = np.zeros_like(image).astype(np.uint8)
  
  for l in range(0, nc):
      idx = image == l
      r[idx] = label_colors[l, 0]
      g[idx] = label_colors[l, 1]
      b[idx] = label_colors[l, 2]
    
  rgb = np.stack([r, g, b], axis=2)
  return rgb


def apply_mask(im, im_pred):
    """
    Overlays the predicted class labels onto an image using the alpha channel.
    This function assumes that the background label is the black color.
    This function is provided as an inspiration for the masking function you should write.
    """
    r_channel, g_channel, b_channel = cv2.split(im_pred)
    alpha_channel = 127 * np.ones(b_channel.shape, dtype=b_channel.dtype)
    # Make background pixels fully transparent
    alpha_channel -= 127 * np.all(im_pred == np.array([0, 0, 0]), axis=2).astype(b_channel.dtype)
    im_pred = cv2.merge((r_channel, g_channel, b_channel, alpha_channel))
    mask = Image.fromarray(im_pred, mode='RGBA')
    masked_img = Image.fromarray(im)
    masked_img.paste(mask, box=None, mask=mask)
    return np.array(masked_img)

# define the model
fcn = models.segmentation.fcn_resnet101(pretrained=True).eval()

# load an image
img = Image.open('./boat.png')
plt.imshow(img); plt.show()

# transform the image
trf = T.Compose([T.ToTensor(), 
                 T.Normalize(mean = [0.485, 0.456, 0.406], 
                             std = [0.229, 0.224, 0.225])])
inp = trf(img).unsqueeze(0)

# pass the input through the net
out = fcn(inp)['out']
print (out.shape)

# calculate labels
om = torch.argmax(out.squeeze(), dim=0).detach().cpu().numpy()
print (np.unique(om))

# show segmentation output
rgb = decode_segmap(om)
plt.imshow(rgb); plt.show()

"""b) Download YourEmail.png and take a class index assigned to you from classes.csv. Modify
segmentation.py so that you predict segmentation mask of this class (by FCN model) on the image given to you and highlight prediction via red mask blended with the original image. Submit this image as YourEmail_predicted.png.
"""

# -*- coding: utf-8 -*-
"""
Based on code from
    https://colab.research.google.com/github/spmallick/learnopencv/blob/master/PyTorch-Segmentation-torchvision/intro-seg.ipynb
"""

from PIL import Image
import matplotlib.pyplot as plt
import torch
from torchvision import models
import numpy as np
import torchvision.transforms as T
import cv2


def decode_segmap(image, nc=21):
  
  label_colors = np.array([(0, 0, 0),  # 0=background
               # 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle
               (128, 0, 0), (0, 128, 0), (255, 0, 0), (0, 0, 128), (128, 0, 128),
               # 6=bus, 7=car, 8=cat, 9=chair, 10=cow
               (0, 128, 128), (128, 128, 128), (64, 0, 0), (192, 0, 0), (64, 128, 0),
               # 11=dining table, 12=dog, 13=horse, 14=motorbike, 15=person
               (192, 128, 0), (64, 0, 128), (192, 0, 128), (64, 128, 128), (192, 128, 128),
               # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor
               (0, 64, 0), (128, 64, 0), (0, 192, 0), (128, 192, 0), (0, 64, 128)])

  r = np.zeros_like(image).astype(np.uint8)
  g = np.zeros_like(image).astype(np.uint8)
  b = np.zeros_like(image).astype(np.uint8)
  
  for l in range(0, nc):
      idx = image == l
      r[idx] = label_colors[l, 0]
      g[idx] = label_colors[l, 1]
      b[idx] = label_colors[l, 2]
    
  rgb = np.stack([r, g, b], axis=2)
  return rgb


def apply_mask(im, im_pred):
    """
    Overlays the predicted class labels onto an image using the alpha channel.
    This function assumes that the background label is the black color.
    This function is provided as an inspiration for the masking function you should write.
    """
    r_channel, g_channel, b_channel = cv2.split(im_pred)
    alpha_channel = 127 * np.ones(b_channel.shape, dtype=b_channel.dtype)
    # Make background pixels fully transparent
    alpha_channel -= 127 * np.all(im_pred == np.array([0, 0, 0]), axis=2).astype(b_channel.dtype)
    im_pred = cv2.merge((r_channel, g_channel, b_channel, alpha_channel))
    mask = Image.fromarray(im_pred, mode='RGBA')
    masked_img = Image.fromarray(im)
    masked_img.paste(mask, box=None, mask=mask)
    a = Image.open(masked_img)
    a = numpy.array(a)
    a[:,:,0] *=0
    a[:,:,1] *=0
    a = Image.fromarray(a)
    a.show()
    return np.array(a)

# define the model
fcn = models.segmentation.fcn_resnet101(pretrained=True).eval()

# load an image
img = Image.open('./SIVARAMT@TCD.IE.png')
plt.imshow(img); plt.show()

# transform the image
trf = T.Compose([T.ToTensor(), 
                 T.Normalize(mean = [0.485, 0.456, 0.406], 
                             std = [0.229, 0.224, 0.225])])
inp = trf(img).unsqueeze(0)

# pass the input through the net
out = fcn(inp)['out']
print (out.shape)

# calculate labels
om = torch.argmax(out.squeeze(), dim=0).detach().cpu().numpy()
print (np.unique(om))

# show segmentation output
rgb = decode_segmap(om,4)
rgb=Image.fromarray(rgb)

# im = rgb.convert('RGBA')
# data = np.array(im)   # "data" is a height x width x 4 numpy array
# red, green, blue, alpha = data.T # Temporarily unpack the bands for readability
# # Replace mask with red
# mask_area = (red != 0) | (blue != 0) | (green != 0)
# data[..., :-1][mask_area.T] = (255, 0, 0)
# im2 = Image.fromarray(data)

plt.imshow(rgb); plt.show()
blended_img=Image.blend(img, rgb, 0.5)
blended_img.save('SIVARAMT@TCD.IE_predicted.png')
plt.imshow(blended_img)

"""c) Decode the groundtruth image YourEmail_mask.png and calculate intersection over union (IOU) with the prediction for the class assigned to you. Report IOU in file YourEmail_iou.csv."""

label_colors = np.array([(0, 0, 0),  # 0=background
               # 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle
               (128, 0, 0), (0, 128, 0), (128, 128, 0), (0, 0, 128), (128, 0, 128),
               # 6=bus, 7=car, 8=cat, 9=chair, 10=cow
               (0, 128, 128), (128, 128, 128), (64, 0, 0), (192, 0, 0), (64, 128, 0),
               # 11=dining table, 12=dog, 13=horse, 14=motorbike, 15=person
               (192, 128, 0), (64, 0, 128), (192, 0, 128), (64, 128, 128), (192, 128, 128),
               # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor
               (0, 64, 0), (128, 64, 0), (0, 192, 0), (128, 192, 0), (0, 64, 128)])

mask_img_given=Image.open('./SIVARAMT@TCD.IE_mask.png')
# rgb_2=Image.fromarray(mask_img_given)
im = mask_img_given.convert('RGB')
data = np.array(im)   
red, green, blue = data.T 
# Replace mask with red
class_seg=3  # 3 for bird and 4 for boat and 15 for people.
mask_area = (red == label_colors[class_seg][0]) & (blue == label_colors[class_seg][2]) & (green == label_colors[class_seg][1])
data[...][mask_area.T] = (255, 0, 0)
not_mask_area=~mask_area
data[...][not_mask_area.T] = (0, 0, 0)
im2 = Image.fromarray(data)
plt.imshow(im2)

intersection = np.logical_and(im2, rgb)
union = np.logical_or(im2, rgb)
iou_score = np.sum(intersection) / np.sum(union)

import pandas as pd
pd.DataFrame.to_csv(pd.Series(iou_score),'SIVARAMT@TCD.IE_iou.csv',index=False,header=None)

print("IOU Score is %f"%iou_score)

"""## REFERENCES

1. Shelhamer, E., Long, J. and Darrell, T. (2016). Fully Convolutional Networks for Semantic Segmentation. [online] arXiv.org.
â€Œ
"""